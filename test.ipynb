{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git_data_utils import loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from git repo...\n",
      "README.md:\n",
      "# Turbo Docs\n",
      "\n",
      "Turbo Docs is a Python script that utilizes OpenAI's GPT API to generate README.md files and docstrings for your Python projects automatically.\n",
      "\n",
      "## Requirements\n",
      "\n",
      "To use Turbo Docs, you will need to have the following Python packages installed:\n",
      "\n",
      "- setuptools\n",
      "- wheel\n",
      "- twine\n",
      "- requests\n",
      "- openai\n",
      "- click\n",
      "- pyperclip\n",
      "- redbaron\n",
      "- gitpython\n",
      "- toml\n",
      "\n",
      "You can install them using the requirements.txt and requirements.dev.txt files in the repository.\n",
      "\n",
      "## Usage\n",
      "\n",
      "To generate a README.md or docstrings for the current directory, you can run the `generate.py` script in the `turbo_docs` folder:\n",
      "\n",
      "```bash\n",
      "# install tubro_docs\n",
      "pip install turbo_docs\n",
      "\n",
      "# command line interface\n",
      "turbo_docs [--copy] [--readme] [--docstring]\n",
      "```\n",
      "\n",
      "You can use the optional flags:\n",
      "- `--copy`: Copy the directory text to clipboard.\n",
      "- `--readme`: Generate README.md file.\n",
      "- `--docstring`: Generate and insert docstrings for each function.\n",
      "\n",
      "## Customization\n",
      "\n",
      "You can modify the files and directories that are excluded from the documentation generation by editing the `exclude.toml` file in the root of the repository. \n",
      "\n",
      "Example syntax to exclude requirements files:\n",
      "\n",
      "```toml\n",
      "exclude = [\n",
      "  \"requirements.*\"\n",
      "]\n",
      "```\n",
      "\n",
      "## Modules\n",
      "\n",
      "Turbo Docs consists of three main modules:\n",
      "\n",
      "1. `turbo_docs.commands.docstring`: Contains functions to generate docstrings for Python functions using GPT-3 text completion model.\n",
      "2. `turbo_docs.commands.readme`: Contains a function to generate a README.md file using the OpenAI API.\n",
      "3. `turbo_docs.utils`: Contains utility functions and decorators for working with CLI options, directories, and the OpenAI API.\n",
      "\n",
      "## Contributing\n",
      "\n",
      "Contributions are always welcome! If you have ideas for improvements or bug fixes, please open an issue or submit a pull request.\n",
      "\n",
      "exclude.toml:\n",
      "# Files or directories to exclude\n",
      "\n",
      "# Example syntax to exlude requirements files\n",
      "#    exclude = [\n",
      "#        \"requirements.*\"\n",
      "#    ]\n",
      "\n",
      "\n",
      ".gitignore:\n",
      "__pycache__\n",
      "venv\n",
      "secrets_manager.py\n",
      "build\n",
      "dist\n",
      "*.egg-info\n",
      "\n",
      "turbo_docs\\generate.py:\n",
      "import click\n",
      "import pyperclip\n",
      "from turbo_docs.commands import docstring as docstring_module\n",
      "from turbo_docs.commands import readme as readme_module\n",
      "from turbo_docs.utils import directory, cli_options\n",
      "\n",
      "\n",
      "@click.command()\n",
      "@cli_options.copy\n",
      "@cli_options.readme\n",
      "@cli_options.docstring\n",
      "def driver(\n",
      "        copy: bool,\n",
      "        readme: bool,\n",
      "        docstring: bool,\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    Generate a README or docstring for the current directory.\n",
      "    \"\"\"\n",
      "    files = directory.get_files()\n",
      "    dir_text = \"\\n\\n\".join(\n",
      "        [f\"{name}:\\n\\n{content}\" for name, content in files.items()])\n",
      "\n",
      "    # Copy directory text to clipboard if specified\n",
      "    if copy:\n",
      "        pyperclip.copy(dir_text)\n",
      "        print(\"(--copy) Directory text copied to clipboard\")\n",
      "\n",
      "    # Generate docstring for each function if specified\n",
      "    if docstring:\n",
      "        docstring_module.docstring(files)\n",
      "\n",
      "    # Generate README.md file if specified\n",
      "    if readme:\n",
      "        readme_module.readme(dir_text)\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    driver()\n",
      "\n",
      "\n",
      "requirements.txt:\n",
      "requests\n",
      "openai\n",
      "click\n",
      "pyperclip\n",
      "redbaron\n",
      "gitpython\n",
      "toml\n",
      "\n",
      "requirements.dev.txt:\n",
      "setuptools\n",
      "wheel\n",
      "twine\n",
      "\n",
      "setup.py:\n",
      "from setuptools import setup, find_packages\n",
      "\n",
      "setup(\n",
      "\tname=\"turbo_docs\",\n",
      "\tversion=\"0.8.4\",\n",
      "\tpackages=find_packages(),\n",
      "\tinstall_requires=[\n",
      "\t\t\"requests\",\n",
      "\t\t\"openai\",\n",
      "\t\t\"click\",\n",
      "\t\t\"pyperclip\",\n",
      "\t\t\"redbaron\",\n",
      "\t\t\"gitpython\",\n",
      "\t],\n",
      "\tentry_points={\n",
      "\t\t\"console_scripts\": [\n",
      "\t\t\t\"turbo_docs=turbo_docs.generate:driver\"\n",
      "\t\t],\n",
      "\t},\n",
      "\tclassifiers=[\n",
      "\t\t\"Development Status :: 3 - Alpha\",\n",
      "\t\t\"Intended Audience :: Developers\",\n",
      "\t\t\"License :: OSI Approved :: MIT License\",\n",
      "\t\t\"Programming Language :: Python :: 3\",\n",
      "\t\t\"Programming Language :: Python :: 3.6\",\n",
      "\t\t\"Programming Language :: Python :: 3.7\",\n",
      "\t\t\"Programming Language :: Python :: 3.8\",\n",
      "\t\t\"Programming Language :: Python :: 3.9\",\n",
      "\t],\n",
      "\tlong_description=open(\"README.md\", encoding=\"utf-8\").read(),\n",
      "    long_description_content_type='text/markdown'\n",
      ")\n",
      "\n",
      "\n",
      "turbo_docs\\commands\\readme.py:\n",
      "import os\n",
      "from turbo_docs.utils import openai_api\n",
      "\n",
      "\n",
      "def readme(text):\n",
      "    \"\"\"\n",
      "    Generate a README.md using openAI API \n",
      "    \"\"\"\n",
      "    readme = \"README.md\"\n",
      "    prompt = f\"You are an expert software developer. Create a well-formatted, user-firendly readme.md documenting the following repo:\\n\\n{text}\"\n",
      "    response = openai_api.gpt_completion_error_handler(prompt)\n",
      "    if response is None:\n",
      "        print(\"Unable to generate README.md, it seems like you have uploaded too many tokens.\\nAdd files to your .gitignore to remove them during the readme generation process.\")\n",
      "    else:\n",
      "        with open(readme, \"w\") as readme_file:\n",
      "            readme_file.write(response)\n",
      "        print(f\"(--readme) Generated README.md\")\n",
      "\n",
      "\n",
      "\n",
      "turbo_docs\\utils\\directory.py:\n",
      "import fnmatch\n",
      "import os\n",
      "import toml\n",
      "from typing import List, Dict\n",
      "\n",
      "\n",
      "def read_exclude_config():\n",
      "    \"\"\"\n",
      "    Reads the exclude.toml file and returns the exclude list.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        with open(\"exclude.toml\", \"r\") as config_file:\n",
      "            config_data = toml.load(config_file)\n",
      "            exclude = config_data.get(\"exclude\", [])\n",
      "    except FileNotFoundError:\n",
      "        exclude = []\n",
      "    return exclude\n",
      "\n",
      "\n",
      "def ignored_files_init() -> List[str]:\n",
      "    \"\"\"\n",
      "    Initialize a list of files to be ignored in directory.\n",
      "    \"\"\"\n",
      "    ignore_files = [\"README.md\", \"tests\", \"setup.py\"]\n",
      "    for file in os.listdir():\n",
      "        if file[0] == \".\":\n",
      "            ignore_files.append(file)\n",
      "    return ignore_files\n",
      "\n",
      "\n",
      "def read_gitignore() -> List[str]:\n",
      "    \"\"\"\n",
      "    Reads in a .gitignore file and returns a list of ignored files.\n",
      "    \"\"\"\n",
      "    ignore_files = []\n",
      "    try:\n",
      "        with open(\".gitignore\", \"r\") as gitignore:\n",
      "            for line in gitignore:\n",
      "                ignore_files.append(line.strip())\n",
      "    except FileNotFoundError:\n",
      "        raise ValueError(\n",
      "            \".gitignore file required for excluding files from documentation generation\"\n",
      "        )\n",
      "    return ignore_files\n",
      "\n",
      "\n",
      "def get_ignore_list() -> List[str]:\n",
      "    \"\"\"\n",
      "    Returns a list of files to be ignored in directory.\n",
      "    \"\"\"\n",
      "    ignore_files = ignored_files_init()\n",
      "    ignore_files.extend(read_exclude_config())\n",
      "    ignore_files.extend(read_gitignore())\n",
      "    return ignore_files\n",
      "\n",
      "\n",
      "def matches_ignore_pattern(filepath: str, ignore_patterns: List[str]) -> bool:\n",
      "    \"\"\"\n",
      "    Check if the given file path matches any of the ignore patterns.\n",
      "    \"\"\"\n",
      "    filepath_parts = filepath.split(os.sep)\n",
      "    return any(\n",
      "        fnmatch.fnmatch(filepath, pattern)\n",
      "        or any(fnmatch.fnmatch(part, pattern) for part in filepath_parts)\n",
      "        for pattern in ignore_patterns\n",
      "    )\n",
      "\n",
      "def read_file_content(filepath: str) -> str:\n",
      "    \"\"\"\n",
      "    Read the content of the file at the given path.\n",
      "    \"\"\"\n",
      "    with open(filepath, \"r\") as f:\n",
      "        content = f.read()\n",
      "    return content.replace(\" \" * 4, \"\\t\").strip()\n",
      "\n",
      "\n",
      "def get_files() -> Dict:\n",
      "    \"\"\"\n",
      "    Retrieve all text from files, excluding filepaths specified by exclude.toml and .gitignore.\n",
      "    \"\"\"\n",
      "    files_dict = {}\n",
      "    ignore_patterns = get_ignore_list()\n",
      "\n",
      "    # Iterate over files\n",
      "    for root, _, files in os.walk(\".\"):\n",
      "        for file in files:\n",
      "            filepath = os.path.join(root, file)\n",
      "\n",
      "            # If file path or its parent directories match any of the ignore patterns\n",
      "            if matches_ignore_pattern(filepath, ignore_patterns):\n",
      "                continue\n",
      "\n",
      "            # If not in ignore, collect file text\n",
      "            content = read_file_content(filepath)\n",
      "            if content:\n",
      "                files_dict[filepath] = content\n",
      "\n",
      "    return files_dict\n",
      "\n",
      "\n",
      "turbo_docs\\utils\\cli_options.py:\n",
      "import click\n",
      "from typing import Callable\n",
      "\n",
      "def copy(func: Callable) -> Callable:\n",
      "    return click.option(\n",
      "        '--copy',\n",
      "        default=False,\n",
      "        is_flag=True,\n",
      "        help='Copy the directory text to clipboard'\n",
      "    )(func)\n",
      "\n",
      "def readme(func: Callable) -> Callable:\n",
      "    return click.option(\n",
      "        '--readme',\n",
      "        default=False,\n",
      "        is_flag=True,\n",
      "        help='Generate README.md file'\n",
      "    )(func)\n",
      "\n",
      "def docstring(func: Callable) -> Callable:\n",
      "    return click.option(\n",
      "        '--docstring',\n",
      "        default=False,\n",
      "        is_flag=True,\n",
      "        help='Generate and insert docstrings for each function'\n",
      "    )(func)\n",
      "\n",
      "\n",
      "turbo_docs\\commands\\docstring.py:\n",
      "from redbaron import RedBaron\n",
      "import textwrap\n",
      "from turbo_docs.utils import openai_api\n",
      "\n",
      "\n",
      "def wrap_text(text):\n",
      "    \"\"\"\n",
      "    Wrap text to 80 chars and break long words.\n",
      "    \"\"\"\n",
      "    line_length = 80\n",
      "\n",
      "    # wrap text to 80 chars\n",
      "    text = \" \".join(text.split(\"\\n\"))\n",
      "    wrapped_text = '\\n'.join(textwrap.wrap(\n",
      "        text, line_length, break_long_words=False))\n",
      "\n",
      "    return wrapped_text\n",
      "\n",
      "\n",
      "def format_docstring(s):\n",
      "    \"\"\"\n",
      "    Formats a docstring to adhere to PEP 8.\n",
      "    \"\"\"\n",
      "    if s.startswith('\"') or s.startswith('\\n'):\n",
      "        return format_docstring(s[1:])\n",
      "\n",
      "    if s.endswith('\"') or s.endswith('\\n'):\n",
      "        return format_docstring(s[:-1])\n",
      "\n",
      "    if \"\\n\\n\" in s:\n",
      "        return format_docstring(s.replace(\"\\n\\n\", \"\\n\"))\n",
      "\n",
      "    if '\"\"\"' in s:\n",
      "        return format_docstring(s.replace('\"\"\"', '\\\\\"\\\\\"\\\\\"'))\n",
      "\n",
      "    wrapped_text = wrap_text(s.strip())\n",
      "    return f'\"\"\"\\n{wrapped_text}\\n\"\"\"'\n",
      "\n",
      "\n",
      "def docstring(files):\n",
      "    \"\"\"\n",
      "    Generate a docstring for Python functions using a GPT-3 text completion model.\n",
      "    \"\"\"\n",
      "    for file_path, content in files.items():\n",
      "        if file_path.split(\".\")[1]:\n",
      "\n",
      "            red = RedBaron(content)\n",
      "            functions = red.find_all(\"def\")\n",
      "            if functions:\n",
      "                for func in functions:\n",
      "                    func_name = func.name\n",
      "                    print(\n",
      "                        f\"(--docstring) Generating docstring for {file_path}.{func_name}\")\n",
      "\n",
      "                    # Remove existing docstring before creating the prompt\n",
      "                    if func.value[0].type == \"string\":\n",
      "                        func.value.pop(0)\n",
      "\n",
      "                    prompt = f'Generate a concise docstring for the following Python function. Do not include argurments and returns.\\n\\n{func.dumps()}'\n",
      "                    docstring = openai_api.gpt_completion_wrapper(prompt)\n",
      "                    docstring_formatted = format_docstring(docstring)\n",
      "                    func.value.insert(0, docstring_formatted)\n",
      "\n",
      "                # Write the modified code back to the file\n",
      "                with open(file_path, \"w\") as f:\n",
      "                    f.write(red.dumps().replace(\"\\t\", \" \" * 4))\n",
      "\n",
      "\n",
      "turbo_docs\\utils\\openai_api.py:\n",
      "import json\n",
      "import os\n",
      "\n",
      "\n",
      "def openai_init():\n",
      "    \"\"\"\n",
      "    Initialize the OpenAI API and prompt the user for their API key if it is not\n",
      "    stored as an environment variable.\n",
      "    \"\"\"\n",
      "    import openai\n",
      "    openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
      "\n",
      "    if not openai.api_key:\n",
      "        print(\"OpenAI API key is not set. Please set it as an environment variable (export OPENAI_API_KEY=<your_api_key>) or enter it below.\")\n",
      "        print(\"If you have not done so already, create an OpenAI account at https://platform.openai.com/overview.\")\n",
      "        openai.api_key = input(\"Secret key:\")\n",
      "    return openai\n",
      "\n",
      "\n",
      "def gpt_completion_wrapper(prompt, openai_package=None, gpt_engine=\"gpt-4\"):\n",
      "    \"\"\"\n",
      "    Provide GPT-3 completions for a given prompt and optional OpenAI package.\n",
      "    \"\"\"\n",
      "    if not openai_package:\n",
      "        openai_package = openai_init()\n",
      "\n",
      "    resp = openai_package.ChatCompletion.create(\n",
      "        model=gpt_engine,\n",
      "        messages=[\n",
      "                {\"role\": \"system\", \"content\": \"You are a helpful coding assistant.\"},\n",
      "                {\"role\": \"user\", \"content\": prompt},\n",
      "            ]\n",
      "        )\n",
      "    return resp['choices'][0]['message']['content'].strip()\n",
      "\n",
      "\n",
      "def gpt_completion_error_handler(prompt):\n",
      "    \"\"\"\n",
      "    Handle errors raised by OpenAI GPT completion API.\n",
      "    \"\"\"\n",
      "    text = None\n",
      "    openai_package = openai_init()\n",
      "\n",
      "    try:\n",
      "        text = gpt_completion_wrapper(prompt, openai_package=openai_package)\n",
      "    except openai_package.error.InvalidRequestError as e:\n",
      "        print(f\"Caught OpenAI API error: {e}\")\n",
      "    return text\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or load the repo data in its entirety\n",
    "repo_name = \"https://github.com/voynow/turbo-docs\"\n",
    "repo_data = loader.load(repo_name)\n",
    "raw_repo_string = loader.repo_to_raw(repo_data)\n",
    "print(raw_repo_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
